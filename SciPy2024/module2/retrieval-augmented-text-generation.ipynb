{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb9665e3-a3e5-40d3-b70b-990ee36df7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "581812da-03d2-407a-aff9-fa621946a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7315b6f-0612-4fc3-9f94-4ab5a0d20e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "613b678f-c0a6-4847-9e5f-cd1712e4b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6533bcd-e294-4fbe-b8d5-6df3053ccc04",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fde1b-f2a4-4c57-8a94-c3dd58a10d74",
   "metadata": {},
   "source": [
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8f06f-b377-4280-9a35-0d2c832904d4",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb892294-f03e-4ad5-9e7b-269526de7a36",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model, thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a06b7f7-8efc-4e6b-8876-3a6bca5dd30f",
   "metadata": {},
   "source": [
    "<center><img src=\"../../images/rag-workflow.webp\" width=\"60%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f220bf9c-6378-4dcc-acb0-dfa32000db77",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430de73-e46c-4029-a460-dbc65184208c",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855b786-5d33-4e4c-b58c-ab8c039deae8",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abe984-c0d4-4b22-b74e-f3b00bbe0260",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb0cdf-ac35-4546-90c5-fd8082633ca5",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbcf1d-499d-4b82-ab23-205ee6d078d3",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86537e0-7c49-43c7-b985-f028b9036c46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048945d-c67d-4ecd-ae07-57f694a5ec52",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab12955-0056-409d-b23a-af27a48dd29d",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a00edab-f0e2-4ac4-b9a9-d64f1f0adc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad8341-6516-4a1a-aab7-ea14cb5a53cc",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec2773-b602-457c-a674-d70bf2971dea",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such represenatations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97f481-33c8-4672-a16c-308e7a6f2dc9",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06b3dc-e387-417c-aec9-01044b5f6a56",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e2701b-d65f-46b4-a84e-940cfc89df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da90bd59-5295-40c4-98c6-fe5c6bdb9d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6605b-d212-45c2-89b3-54cf3eba5303",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1176aa-6658-43d8-b3d5-c02ff4827690",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9d732-fd39-4292-b68d-570888409d27",
   "metadata": {},
   "source": [
    "> We now embed our relevant documents (knowledge base) into a pre-trained embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf20f86-19d8-4e16-98d7-97b69f8f889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5a5e70-60a5-4270-b58c-b2f69e724193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3beed7-0042-4142-9226-8371ee2ef38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1a2a99-c7a6-45c0-879d-e3ca7f69cc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10c62ff-cde7-4ad8-b9ff-09f8e54a22e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.030922148376703262, 0.039250507950782776, 0.01346262451261282]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6a255-2c4a-4a6e-ad53-cd7865c2165e",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09296df-1f27-4c9e-ad66-0b8ac874f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.7257]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", util.dot_score(query_result, embeddings_model.embed_query(\"Mars is a planet in the solar system.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044ccda7-acfe-406d-a5a9-a9c30f6390cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.0174]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", util.dot_score(query_result, embeddings_model.embed_query(\"Hello Tacoma.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb875a2-5daf-4647-9c13-52a5bd6929cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 256\n"
     ]
    }
   ],
   "source": [
    "# Get the value of the max sequence_length\n",
    "print(f\"Model's maximum sequence length: {SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fc10b-69e8-4a6d-b161-4bb809c59262",
   "metadata": {},
   "source": [
    "So, we should ensure that our chunk sizes or individual documents are below this limit because any longer chunk will be truncated before processing, thus losing critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92142a-c8e4-4421-aa16-809d8b1ad4e0",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07ea7d-cd51-470c-867a-e9c0aa36cf84",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the notebook in the Appendix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75a9f43-fc9d-4b6c-a898-ad53ab7d5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix module paths\n",
    "qdrant_path = \"../../resources/data/scipy_qdrant/\"\n",
    "\n",
    "# TODO: Change collection name to \n",
    "qdrant_collection = \"arxiv_astro-ph_abstracts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484935dc-a3f5-4742-a6bc-38866a127ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ea8e13-73b0-43ed-b705-26205f4de4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Qdrant collection 'arxiv_astro-ph_abstracts'\n"
     ]
    }
   ],
   "source": [
    "# Setting up Qdrant\n",
    "if os.path.exists(qdrant_path):\n",
    "    print(f\"Loading existing Qdrant collection '{qdrant_collection}'\")\n",
    "    \n",
    "    client = QdrantClient(path=qdrant_path)\n",
    "    \n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=qdrant_collection,\n",
    "        embeddings=model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b1723-0992-4d47-86c5-24b04d816df6",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a98db8-dead-44c7-a26b-0d0d5319d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "# mmr stands for  Maximum Marginal Relevance \n",
    "# \"MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\"\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "469ce9c5-ce25-41c3-a836-db7df31c3bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"  Dark matter is one of the greatest unsolved mysteries in cosmology at the\\npresent time. About 80% of the universe's gravitating matter is non-luminous,\\nand its nature and distribution are for the most part unknown. In this paper,\\nwe will outline the history, astrophysical evidence, candidates, and detection\\nmethods of dark matter, with the goal to give the reader an accessible but\\nrigorous introduction to the puzzle of dark matter. This review targets\\nadvanced students and researchers new to the field of dark matter, and includes\\nan extensive list of references for further study.\\n\", metadata={'id': '1006.2483', 'title': 'Dark Matter: A Primer', 'categories': 'hep-ph astro-ph.CO', '_id': '70c556bd7c644b62aa8ef4e50d312e51', '_collection_name': 'arxiv_astro-ph_abstracts'}),\n",
       " Document(page_content='  It is suggested that Dark Matter in the Universe is made of stars and black\\nholes of WIMP matter.\\n', metadata={'id': 'astro-ph/0204375', 'title': 'WIMP Stars as Dark Matter in the Universe', 'categories': 'astro-ph', '_id': 'f8b6b3c92e1449ca9ca0be5a8b4c10e1', '_collection_name': 'arxiv_astro-ph_abstracts'})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is dark matter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff3542b-4469-4432-befb-6f3b725a3c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  I present simple analytical equations to transform proper motion vectors from\\nequatorial to Galactic coordinates.\\n', metadata={'id': '1306.2945', 'title': 'Transformation of the equatorial proper motion to the Galactic system', 'categories': 'astro-ph.IM', '_id': '1439d4c0b3fb4aec9619d9a1cbfdfc0a', '_collection_name': 'arxiv_astro-ph_abstracts'}),\n",
       " Document(page_content='  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\\nassigning physical coordinates to FITS image pixels. This paper implements this\\nmethod for all spherical map projections likely to be of interest in astronomy.\\nThe new methods encompass existing informal FITS spherical coordinate\\nconventions and translations from them are described. Detailed examples of\\nheader interpretation and construction are given.\\n', metadata={'id': 'astro-ph/0207413', 'title': 'Representations of celestial coordinates in FITS', 'categories': 'astro-ph', '_id': '31329efafff241c8a6c8891d490ad1e5', '_collection_name': 'arxiv_astro-ph_abstracts'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How can I perform celestial coordinate transformations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41a270b6-05a0-4f3f-80a1-21b7f98cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec307d1d-8e83-45f9-8048-43c07974a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dark matter is one of the greatest unsolved mysteries in cosmology at the\n",
      "present time. About 80% of the universe's gravitating matter is non-luminous,\n",
      "and its nature and distribution are for the most part unknown. In this paper,\n",
      "we will outline the history, astrophysical evidence, candidates, and detection\n",
      "methods of dark matter, with the goal to give the reader an accessible but\n",
      "rigorous introduction to the puzzle of dark matter. This review targets\n",
      "advanced students and researchers new to the field of dark matter, and includes\n",
      "an extensive list of references for further study.\n",
      "\n",
      "\n",
      "  It is suggested that Dark Matter in the Universe is made of stars and black\n",
      "holes of WIMP matter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"What is dark matter?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f90230bb-b3fe-47a1-954d-e38ff39c35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I present simple analytical equations to transform proper motion vectors from\n",
      "equatorial to Galactic coordinates.\n",
      "\n",
      "\n",
      "  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\n",
      "assigning physical coordinates to FITS image pixels. This paper implements this\n",
      "method for all spherical map projections likely to be of interest in astronomy.\n",
      "The new methods encompass existing informal FITS spherical coordinate\n",
      "conventions and translations from them are described. Detailed examples of\n",
      "header interpretation and construction are given.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"How can I perform celestial coordinate transformations?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260d5b4-b95c-4e76-804b-e4ed69492313",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff927dd-8eb3-4632-88b6-9a04e9907cb5",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0afedaa-feb8-4d6f-9adc-85694008967f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "# TODO: Fix model path to cache folder\n",
    "olmo = LlamaCpp(\n",
    "    model_path=\"../../resources/models/OLMo-7B-Instruct-GGUF/OLMo-7B-Instruct-Q4_K_M.gguf\",\n",
    "    temperature=0.8,\n",
    "    verbose=False,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da3e6e4f-a9c9-4634-8004-761a54727d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata['tokenizer.chat_template'], \n",
    "    template_format=\"jinja2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ee03d9-fba6-408d-8db7-1082affc8c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context:   Dark matter is one of the greatest unsolved mysteries in cosmology at the\\npresent time. About 80% of the universe's gravitating matter is non-luminous,\\nand its nature and distribution are for the most part unknown. In this paper,\\nwe will outline the history, astrophysical evidence, candidates, and detection\\nmethods of dark matter, with the goal to give the reader an accessible but\\nrigorous introduction to the puzzle of dark matter. This review targets\\nadvanced students and researchers new to the field of dark matter, and includes\\nan extensive list of references for further study.\\n\\n\\n  It is suggested that Dark Matter in the Universe is made of stars and black\\nholes of WIMP matter.\\n\\n            \\n            Question: What is dark matter?\\n\\n\\n<|assistant|>\\n\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "context = format_docs(retriever.invoke(\"What is dark matter?\"))\n",
    "\n",
    "question = \"What is dark matter?\"\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\"\n",
    "        }\n",
    "    ], \n",
    "    add_generation_prompt=True, \n",
    "    eos_token=\"<|endoftext|>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f1a21-9ddf-4a96-9953-0c32dc8b5c76",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12494b46-7aaa-4e60-8059-d35c11461682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82afc357-6be3-443c-83a6-94016dab9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the prompt template and olmo\n",
    "llm_chain = prompt_template | olmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "749ef251-4f48-42b3-ba4a-fe0a89f311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26a055b1-bd1f-4c70-b985-c768ab70d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical entity that is currently the most popular solution to explaining the motion and observed properties of galaxies, stars, and other celestial bodies in the universe. Although it's difficult to visualize, its presence can be inferred from various astronomical observations. In this context, dark matter is made up of non-luminous materials that do not emit, reflect, or absorb light. Instead, their existence and properties are determined through their gravitational effects on visible matter like stars, gas, and dust (1).\n",
      "\n",
      "The term \"dark matter\" originated from the observation that the distribution and motions of celestial bodies in the universe don't match up with the visible matter alone. Dark matter is estimated to account for around 85% of the total mass-energy content of the universe (2), which is significantly more massive than any known form of matter, including stars and galaxies.\n",
      "\n",
      "To date, dark matter remains one of the greatest unsolved mysteries in cosmology because its nature, composition, distribution, and interactions remain unknown. Several astrophysical observations have suggested that dark matter may consist of weakly interacting massive particles (WIMPs) or other yet-to-be-discovered types of matter (2).\n",
      "\n",
      "In this review paper, authors propose that dark matter"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Dark matter is a theoretical entity that is currently the most popular solution to explaining the motion and observed properties of galaxies, stars, and other celestial bodies in the universe. Although it\\'s difficult to visualize, its presence can be inferred from various astronomical observations. In this context, dark matter is made up of non-luminous materials that do not emit, reflect, or absorb light. Instead, their existence and properties are determined through their gravitational effects on visible matter like stars, gas, and dust (1).\\n\\nThe term \"dark matter\" originated from the observation that the distribution and motions of celestial bodies in the universe don\\'t match up with the visible matter alone. Dark matter is estimated to account for around 85% of the total mass-energy content of the universe (2), which is significantly more massive than any known form of matter, including stars and galaxies.\\n\\nTo date, dark matter remains one of the greatest unsolved mysteries in cosmology because its nature, composition, distribution, and interactions remain unknown. Several astrophysical observations have suggested that dark matter may consist of weakly interacting massive particles (WIMPs) or other yet-to-be-discovered types of matter (2).\\n\\nIn this review paper, authors propose that dark matter'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chain with a question and other parameters. \n",
    "llm_chain.invoke(\n",
    "    {\n",
    "        \"messages\":\n",
    "            [{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "    \n",
    "                Context: {context}\n",
    "                \n",
    "                Question: {question}\"\"\"\n",
    "            }\n",
    "        ], \n",
    "        \"add_generation_prompt\": True, \n",
    "        \"eos_token\": \"<|endoftext|>\",\n",
    "    },\n",
    "    config={\n",
    "        'callbacks' : [StreamingStdOutCallbackHandler()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c6ac2-3402-41ac-9537-7bac62547f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
