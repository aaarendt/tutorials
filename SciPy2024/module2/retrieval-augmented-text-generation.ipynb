{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9665e3-a3e5-40d3-b70b-990ee36df7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581812da-03d2-407a-aff9-fa621946a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7315b6f-0612-4fc3-9f94-4ab5a0d20e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "613b678f-c0a6-4847-9e5f-cd1712e4b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6533bcd-e294-4fbe-b8d5-6df3053ccc04",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fde1b-f2a4-4c57-8a94-c3dd58a10d74",
   "metadata": {},
   "source": [
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8f06f-b377-4280-9a35-0d2c832904d4",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb892294-f03e-4ad5-9e7b-269526de7a36",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model, thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a06b7f7-8efc-4e6b-8876-3a6bca5dd30f",
   "metadata": {},
   "source": [
    "<center><img src=\"../../images/rag-workflow.webp\" width=\"60%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f220bf9c-6378-4dcc-acb0-dfa32000db77",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430de73-e46c-4029-a460-dbc65184208c",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855b786-5d33-4e4c-b58c-ab8c039deae8",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abe984-c0d4-4b22-b74e-f3b00bbe0260",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb0cdf-ac35-4546-90c5-fd8082633ca5",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbcf1d-499d-4b82-ab23-205ee6d078d3",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86537e0-7c49-43c7-b985-f028b9036c46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048945d-c67d-4ecd-ae07-57f694a5ec52",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab12955-0056-409d-b23a-af27a48dd29d",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a00edab-f0e2-4ac4-b9a9-d64f1f0adc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad8341-6516-4a1a-aab7-ea14cb5a53cc",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec2773-b602-457c-a674-d70bf2971dea",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such represenatations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97f481-33c8-4672-a16c-308e7a6f2dc9",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06b3dc-e387-417c-aec9-01044b5f6a56",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e2701b-d65f-46b4-a84e-940cfc89df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da90bd59-5295-40c4-98c6-fe5c6bdb9d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6605b-d212-45c2-89b3-54cf3eba5303",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1176aa-6658-43d8-b3d5-c02ff4827690",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9d732-fd39-4292-b68d-570888409d27",
   "metadata": {},
   "source": [
    "> We now embed our relevant documents (knowledge base) into a pre-trained embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf20f86-19d8-4e16-98d7-97b69f8f889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5a5e70-60a5-4270-b58c-b2f69e724193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3beed7-0042-4142-9226-8371ee2ef38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1a2a99-c7a6-45c0-879d-e3ca7f69cc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10c62ff-cde7-4ad8-b9ff-09f8e54a22e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05409970507025719, 0.07589351385831833, -0.04195251315832138]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6a255-2c4a-4a6e-ad53-cd7865c2165e",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09296df-1f27-4c9e-ad66-0b8ac874f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.7926]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", util.dot_score(query_result, embeddings_model.embed_query(\"Mars is a planet in the solar system.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044ccda7-acfe-406d-a5a9-a9c30f6390cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.0877]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", util.dot_score(query_result, embeddings_model.embed_query(\"Hello Tacoma.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb875a2-5daf-4647-9c13-52a5bd6929cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 128\n"
     ]
    }
   ],
   "source": [
    "# Get the value of the max sequence_length\n",
    "print(f\"Model's maximum sequence length: {SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2').max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fc10b-69e8-4a6d-b161-4bb809c59262",
   "metadata": {},
   "source": [
    "So, we should ensure that our chunk sizes or individual documents are below this limit because any longer chunk will be truncated before processing, thus losing critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92142a-c8e4-4421-aa16-809d8b1ad4e0",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07ea7d-cd51-470c-867a-e9c0aa36cf84",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the notebook in the Appendix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a75a9f43-fc9d-4b6c-a898-ad53ab7d5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix module paths\n",
    "qdrant_path = \"../../resources/data/qdrant/scipy_qdrant/\"\n",
    "\n",
    "# TODO: Change collection name to \n",
    "qdrant_collection = \"arxiv_astro-ph_abstracts_astropy_github_documentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ea8e13-73b0-43ed-b705-26205f4de4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Qdrant collection 'arxiv_astro-ph_abstracts_astropy_github_documentation'\n"
     ]
    }
   ],
   "source": [
    "# Setting up Qdrant\n",
    "if os.path.exists(qdrant_path):\n",
    "    print(f\"Loading existing Qdrant collection '{qdrant_collection}'\")\n",
    "    \n",
    "    client = QdrantClient(path=qdrant_path)\n",
    "    \n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=qdrant_collection,\n",
    "        embeddings=embeddings_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b1723-0992-4d47-86c5-24b04d816df6",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a98db8-dead-44c7-a26b-0d0d5319d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "# mmr stands for  Maximum Marginal Relevance \n",
    "# \"MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\"\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "469ce9c5-ce25-41c3-a836-db7df31c3bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  Modern cosmology successfully deals with the origin and the evolution of the\\nUniverse at large scales, but it is unable to completely answer the question\\nabout the nature of the fundamental objects that it is describing. As a matter\\nof fact, about 95\\\\% of the constituents of the Universe is indeed completely\\nunknown: it cannot be described in terms of known particles. Despite intense\\nefforts to shed light on this literal darkness by dark matter and dark energy\\ndirect and indirect searches, not much progress has been made so far. In this\\nwork, we take a different perspective by reviewing and elaborating an old idea\\nof studying the mass-radius distribution of structures in the Universe in\\nrelationship with the fundamental forces acting on them. As we will describe in\\ndetail, the distribution of the observed structures in the Universe is not\\ncompletely random, but it reflects the intimate features of the involved\\nparticles and the nature of the fundamental interactions at play. The observed\\nstructures cluster in restricted regions of the mass-radius diagram linked to\\nknown particles, with the remarkable exception of very large structures that\\nseem to be linked to an unknown particle in the sub-eV mass range. We\\nconjecture that this new particle is a self-interacting dark matter candidate.\\n', metadata={'id': 2112.03755, 'title': 'A new approach to dark matter from the mass-radius diagram of the\\n  Universe', '_id': 'fc4d40da0dc7462091b258df45f01e30', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content='  We calculate the accurate spectrum of the stochastic gravitational wave\\nbackground from U(1) gauge fields produced by axion dark matter. The explosive\\nproduction of gauge fields soon invalidates the applicability of the linear\\nanalysis and one needs nonlinear schemes. We make use of numerical lattice\\nsimulations to properly follow the nonlinear dynamics such as backreaction and\\nrescattering which gives important contributions to the emission of\\ngravitational waves. It turns out that the axion with the decay constant $f\\n\\\\sim 10^{16}$ GeV which gives the correct dark matter abundance predicts the\\ncircularly polarized gravitational wave signature detectable by SKA. We also\\nshow that the resulting gravitational wave spectrum has a potential to explain\\nNANOGrav 12.5 year data.\\n', metadata={'id': 2010.1099, 'title': 'Nano-Hz gravitational wave signature from axion dark matter', '_id': '04e3a40776af4041af66b82cfd427537', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is dark matter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ff3542b-4469-4432-befb-6f3b725a3c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\\nassigning physical coordinates to FITS image pixels. This paper implements this\\nmethod for all spherical map projections likely to be of interest in astronomy.\\nThe new methods encompass existing informal FITS spherical coordinate\\nconventions and translations from them are described. Detailed examples of\\nheader interpretation and construction are given.\\n', metadata={'id': 'astro-ph/0207413', 'title': 'Representations of celestial coordinates in FITS', '_id': '97984f0ccf1c445cad6c671ea68446a4', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content='  We successfully measured the trigonometric parallax of Sagittarius A* (Sgr\\nA*) to be $117\\\\pm17$ micro-arcseconds ($\\\\mu$as) using the VLBI Exploration of\\nRadio Astrometry (VERA) with the newly developed broad-band signal-processing\\nsystem named OCTAVE-DAS. The measured parallax corresponds to a Galactocentric\\ndistance at the Sun of $R_0 = 8.5^{+1.5}_{-1.1}$ kpc. By combining the\\nastrometric results with VERA and the Very Long Baseline Array (VLBA) over a\\nmonitoring period of 25 years, the proper motion of Sgr A* is obtained to be\\n$(\\\\mu_\\\\alpha, \\\\mu_\\\\delta) = (-3.133\\\\pm0.003, -5.575\\\\pm0.005)$ mas yr$^{-1}$ in\\nequatorial coordinates, corresponding to $(\\\\mu_l, \\\\mu_b) = (-6.391\\\\pm0.005,\\n-0.230\\\\pm0.004)$ mas yr$^{-1}$ in Galactic coordinates. This gives an angular\\norbital velocity of the Sun of $\\\\Omega_\\\\odot = 30.30 \\\\pm 0.02$ km s$^{-1}$\\nkpc$^{-1}$. We find upper limits to the core wander, $\\\\Delta \\\\theta < 0.20$ mas\\n(1.6 AU), peculiar motion, $\\\\Delta \\\\mu < 0.10$ mas yr$^{-1}$ (3.7 km s$^{-1}$),\\nand acceleration, $a < 2.6$ $\\\\mu$as yr$^{-2}$ (0.10 km s$^{-1}$ yr$^{-1}$) for\\nSgr A*. Thus, we obtained upper mass limits of $\\\\approx$ 3 $\\\\times$\\n10$^{4}$$M_{\\\\odot}$ and $\\\\approx$ 3 $\\\\times$ 10$^{3}$$M_{\\\\odot}$ for the\\nsupposed intermediate-mass black holes at 0.1 and 0.01 pc from the Galactic\\ncenter, respectively.\\n', metadata={'id': 2401.02312, 'title': 'Trigonometric parallax and proper motion of Sagittarius A* measured by\\n  VERA using the new broad-band back-end system OCTAVE-DAS', '_id': 'bbb1fb028da24f0d98aad38f281dc9df', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How can I perform celestial coordinate transformations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a270b6-05a0-4f3f-80a1-21b7f98cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec307d1d-8e83-45f9-8048-43c07974a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Modern cosmology successfully deals with the origin and the evolution of the\n",
      "Universe at large scales, but it is unable to completely answer the question\n",
      "about the nature of the fundamental objects that it is describing. As a matter\n",
      "of fact, about 95\\% of the constituents of the Universe is indeed completely\n",
      "unknown: it cannot be described in terms of known particles. Despite intense\n",
      "efforts to shed light on this literal darkness by dark matter and dark energy\n",
      "direct and indirect searches, not much progress has been made so far. In this\n",
      "work, we take a different perspective by reviewing and elaborating an old idea\n",
      "of studying the mass-radius distribution of structures in the Universe in\n",
      "relationship with the fundamental forces acting on them. As we will describe in\n",
      "detail, the distribution of the observed structures in the Universe is not\n",
      "completely random, but it reflects the intimate features of the involved\n",
      "particles and the nature of the fundamental interactions at play. The observed\n",
      "structures cluster in restricted regions of the mass-radius diagram linked to\n",
      "known particles, with the remarkable exception of very large structures that\n",
      "seem to be linked to an unknown particle in the sub-eV mass range. We\n",
      "conjecture that this new particle is a self-interacting dark matter candidate.\n",
      "\n",
      "\n",
      "  We calculate the accurate spectrum of the stochastic gravitational wave\n",
      "background from U(1) gauge fields produced by axion dark matter. The explosive\n",
      "production of gauge fields soon invalidates the applicability of the linear\n",
      "analysis and one needs nonlinear schemes. We make use of numerical lattice\n",
      "simulations to properly follow the nonlinear dynamics such as backreaction and\n",
      "rescattering which gives important contributions to the emission of\n",
      "gravitational waves. It turns out that the axion with the decay constant $f\n",
      "\\sim 10^{16}$ GeV which gives the correct dark matter abundance predicts the\n",
      "circularly polarized gravitational wave signature detectable by SKA. We also\n",
      "show that the resulting gravitational wave spectrum has a potential to explain\n",
      "NANOGrav 12.5 year data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"What is dark matter?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f90230bb-b3fe-47a1-954d-e38ff39c35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\n",
      "assigning physical coordinates to FITS image pixels. This paper implements this\n",
      "method for all spherical map projections likely to be of interest in astronomy.\n",
      "The new methods encompass existing informal FITS spherical coordinate\n",
      "conventions and translations from them are described. Detailed examples of\n",
      "header interpretation and construction are given.\n",
      "\n",
      "\n",
      "  We successfully measured the trigonometric parallax of Sagittarius A* (Sgr\n",
      "A*) to be $117\\pm17$ micro-arcseconds ($\\mu$as) using the VLBI Exploration of\n",
      "Radio Astrometry (VERA) with the newly developed broad-band signal-processing\n",
      "system named OCTAVE-DAS. The measured parallax corresponds to a Galactocentric\n",
      "distance at the Sun of $R_0 = 8.5^{+1.5}_{-1.1}$ kpc. By combining the\n",
      "astrometric results with VERA and the Very Long Baseline Array (VLBA) over a\n",
      "monitoring period of 25 years, the proper motion of Sgr A* is obtained to be\n",
      "$(\\mu_\\alpha, \\mu_\\delta) = (-3.133\\pm0.003, -5.575\\pm0.005)$ mas yr$^{-1}$ in\n",
      "equatorial coordinates, corresponding to $(\\mu_l, \\mu_b) = (-6.391\\pm0.005,\n",
      "-0.230\\pm0.004)$ mas yr$^{-1}$ in Galactic coordinates. This gives an angular\n",
      "orbital velocity of the Sun of $\\Omega_\\odot = 30.30 \\pm 0.02$ km s$^{-1}$\n",
      "kpc$^{-1}$. We find upper limits to the core wander, $\\Delta \\theta < 0.20$ mas\n",
      "(1.6 AU), peculiar motion, $\\Delta \\mu < 0.10$ mas yr$^{-1}$ (3.7 km s$^{-1}$),\n",
      "and acceleration, $a < 2.6$ $\\mu$as yr$^{-2}$ (0.10 km s$^{-1}$ yr$^{-1}$) for\n",
      "Sgr A*. Thus, we obtained upper mass limits of $\\approx$ 3 $\\times$\n",
      "10$^{4}$$M_{\\odot}$ and $\\approx$ 3 $\\times$ 10$^{3}$$M_{\\odot}$ for the\n",
      "supposed intermediate-mass black holes at 0.1 and 0.01 pc from the Galactic\n",
      "center, respectively.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"How can I perform celestial coordinate transformations?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260d5b4-b95c-4e76-804b-e4ed69492313",
   "metadata": {},
   "source": [
    "## Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff927dd-8eb3-4632-88b6-9a04e9907cb5",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e0afedaa-feb8-4d6f-9adc-85694008967f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "# TODO: Fix model path to cache folder\n",
    "olmo = LlamaCpp(\n",
    "    model_path=\"../../resources/models/OLMo-7B-Instruct-GGUF/OLMo-7B-Instruct-Q4_K_M.gguf\",\n",
    "    temperature=0.8,\n",
    "    verbose=False,  \n",
    "    n_ctx=2048,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "da3e6e4f-a9c9-4634-8004-761a54727d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata['tokenizer.chat_template'], \n",
    "    template_format=\"jinja2\",\n",
    "    partial_variables={\"add_generation_prompt\": True, \"eos_token\": \"<|endoftext|>\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5b0976d6-392e-440a-b929-a95e4daa13df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['messages'], partial_variables={'add_generation_prompt': True, 'eos_token': '<|endoftext|>'}, template=\"{{ eos_token }}{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", template_format='jinja2')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0d8458f5-24db-47bc-9cc5-81162f581e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context:   Modern cosmology successfully deals with the origin and the evolution of the\\nUniverse at large scales, but it is unable to completely answer the question\\nabout the nature of the fundamental objects that it is describing. As a matter\\nof fact, about 95\\\\% of the constituents of the Universe is indeed completely\\nunknown: it cannot be described in terms of known particles. Despite intense\\nefforts to shed light on this literal darkness by dark matter and dark energy\\ndirect and indirect searches, not much progress has been made so far. In this\\nwork, we take a different perspective by reviewing and elaborating an old idea\\nof studying the mass-radius distribution of structures in the Universe in\\nrelationship with the fundamental forces acting on them. As we will describe in\\ndetail, the distribution of the observed structures in the Universe is not\\ncompletely random, but it reflects the intimate features of the involved\\nparticles and the nature of the fundamental interactions at play. The observed\\nstructures cluster in restricted regions of the mass-radius diagram linked to\\nknown particles, with the remarkable exception of very large structures that\\nseem to be linked to an unknown particle in the sub-eV mass range. We\\nconjecture that this new particle is a self-interacting dark matter candidate.\\n\\n\\n  We calculate the accurate spectrum of the stochastic gravitational wave\\nbackground from U(1) gauge fields produced by axion dark matter. The explosive\\nproduction of gauge fields soon invalidates the applicability of the linear\\nanalysis and one needs nonlinear schemes. We make use of numerical lattice\\nsimulations to properly follow the nonlinear dynamics such as backreaction and\\nrescattering which gives important contributions to the emission of\\ngravitational waves. It turns out that the axion with the decay constant $f\\n\\\\sim 10^{16}$ GeV which gives the correct dark matter abundance predicts the\\ncircularly polarized gravitational wave signature detectable by SKA. We also\\nshow that the resulting gravitational wave spectrum has a potential to explain\\nNANOGrav 12.5 year data.\\n\\n            \\n            Question: What is dark matter?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "\n",
    "question = \"What is dark matter?\"\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "23dc552e-c751-4c17-8fb6-4245c675e973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context:   In Paper I, Greisen & Calabretta (2002) describe a generalized method for\\nassigning physical coordinates to FITS image pixels. This paper implements this\\nmethod for all spherical map projections likely to be of interest in astronomy.\\nThe new methods encompass existing informal FITS spherical coordinate\\nconventions and translations from them are described. Detailed examples of\\nheader interpretation and construction are given.\\n\\n\\n  We successfully measured the trigonometric parallax of Sagittarius A* (Sgr\\nA*) to be $117\\\\pm17$ micro-arcseconds ($\\\\mu$as) using the VLBI Exploration of\\nRadio Astrometry (VERA) with the newly developed broad-band signal-processing\\nsystem named OCTAVE-DAS. The measured parallax corresponds to a Galactocentric\\ndistance at the Sun of $R_0 = 8.5^{+1.5}_{-1.1}$ kpc. By combining the\\nastrometric results with VERA and the Very Long Baseline Array (VLBA) over a\\nmonitoring period of 25 years, the proper motion of Sgr A* is obtained to be\\n$(\\\\mu_\\\\alpha, \\\\mu_\\\\delta) = (-3.133\\\\pm0.003, -5.575\\\\pm0.005)$ mas yr$^{-1}$ in\\nequatorial coordinates, corresponding to $(\\\\mu_l, \\\\mu_b) = (-6.391\\\\pm0.005,\\n-0.230\\\\pm0.004)$ mas yr$^{-1}$ in Galactic coordinates. This gives an angular\\norbital velocity of the Sun of $\\\\Omega_\\\\odot = 30.30 \\\\pm 0.02$ km s$^{-1}$\\nkpc$^{-1}$. We find upper limits to the core wander, $\\\\Delta \\\\theta < 0.20$ mas\\n(1.6 AU), peculiar motion, $\\\\Delta \\\\mu < 0.10$ mas yr$^{-1}$ (3.7 km s$^{-1}$),\\nand acceleration, $a < 2.6$ $\\\\mu$as yr$^{-2}$ (0.10 km s$^{-1}$ yr$^{-1}$) for\\nSgr A*. Thus, we obtained upper mass limits of $\\\\approx$ 3 $\\\\times$\\n10$^{4}$$M_{\\\\odot}$ and $\\\\approx$ 3 $\\\\times$ 10$^{3}$$M_{\\\\odot}$ for the\\nsupposed intermediate-mass black holes at 0.1 and 0.01 pc from the Galactic\\ncenter, respectively.\\n\\n            \\n            Question: How can I perform celestial coordinate transformations?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "question = \"How can I perform celestial coordinate transformations?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c270d-60fc-4b84-be3d-f9897a189dba",
   "metadata": {},
   "source": [
    "One way to generate the response with OLMo is to build `context` using the `question` beforehand, as shown above, create an llm_chain then `invoke` it with `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5e4f5393-e92f-44ee-8a29-46f5d5a5b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the prompt template and olmo\n",
    "llm_chain = prompt_template | olmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e524031d-d379-46c9-b177-086e6a4d7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical particle or collection of particles that, despite being invisible, is believed to make up approximately 95% of the matter in the universe. It is called \"dark\" because it does not emit light and therefore cannot be seen like other particles, such as those comprising stars and galaxies. Dark matter is thought to influence the motion and distribution of stars, galaxies, and entire celestial bodies due to its massive presence. Its properties are not well understood, but scientists currently believe it could be a type of weakly interacting massive particle (WIMP) or an axion, among other possibilities."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Dark matter is a theoretical particle or collection of particles that, despite being invisible, is believed to make up approximately 95% of the matter in the universe. It is called \"dark\" because it does not emit light and therefore cannot be seen like other particles, such as those comprising stars and galaxies. Dark matter is thought to influence the motion and distribution of stars, galaxies, and entire celestial bodies due to its massive presence. Its properties are not well understood, but scientists currently believe it could be a type of weakly interacting massive particle (WIMP) or an axion, among other possibilities.'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "# Invoke the chain with a question and other parameters. \n",
    "llm_chain.invoke(\n",
    "    {\n",
    "        \"messages\":\n",
    "            [{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "    \n",
    "                Context: {context}\n",
    "                \n",
    "                Question: {question}\"\"\"\n",
    "            }\n",
    "        ], \n",
    "    },\n",
    "    config={\n",
    "        'callbacks' : [StreamingStdOutCallbackHandler()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b826474-9d60-4dfc-ad22-7012d1e90fd2",
   "metadata": {},
   "source": [
    "We can further use [LangChain's convenience functions](https://python.langchain.com/v0.2/docs/tutorials/rag/#built-in-chains) to streamline our pipeline using [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) and [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd3349-f0d0-4645-93af-533561ff3da6",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30370bee-5e4f-49ef-976c-a1d18eb1064e",
   "metadata": {},
   "source": [
    "On looking its signature, notice that it accepts `prompt` argument of type `BasePromptTemplate` but it needs input keys as `context` and `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7e9f2d4b-311f-49cd-b8f2-acb115beee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line and run the cell\n",
    "#create_stuff_documents_chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8af92304-e15d-407f-bcdb-ea797fe4db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], template='<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context.                             Context: {context}                             Question: {input}\\n\\n\\n<|assistant|>\\n\\n')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we can tranform our prompt_template, so that it accepts `context` and `input` as input_variables\n",
    "transformed_prompt_template = PromptTemplate.from_template(\n",
    "    prompt_template.partial(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"You are an astrophysics expert. Please answer the question on astrophysics based on the following context. \\\n",
    "                            Context: {context} \\\n",
    "                            Question: {input}\"\n",
    "            }\n",
    "        ]\n",
    "    ).format()\n",
    ")\n",
    "transformed_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f30853bb-6b4f-44a2-9a72-78748a7d290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=olmo, \n",
    "    prompt=transformed_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24ea7e-6020-4573-9a6d-45309b04f521",
   "metadata": {},
   "source": [
    "We can run this by passing in the context directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "96cb5068-871a-4699-b765-6a8a4d4a4ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Dark Matter is a theoretical concept in astrophysics and cosmology that describes the existence of a type of matter that cannot be seen or detected using traditional methods such as light, energy, or radiation. In contrast to visible matter, which makes up approximately 85% of the universe's total mass-energy content, dark matter constitutes about 25% of this mass. It does not emit, absorb, or reflect any electromagnetic radiation and is therefore invisible to us.\\n\\nDark Matter is an essential component in modern cosmology, as its presence is required to reconcile the mathematical predictions of cosmological models with the large-scale structures observed in the universe such as galaxies and galaxy clusters. These structures form due to the gravitational clustering of dark matter particles. The nature of dark matter remains a mystery, and it is still an active area of research.\\n\\nOne of the possible candidates for dark matter is the axion, which was first introduced to solve a problem in fundamental physics, namely the strong CP (axial vector) problem. An axion is a hypothetical particle that could have been produced during the early universe through a mechanism called the Peccei-Quinn (PQ) mechanism. The decay constant $f$ for the axion, which is used to describe its properties, is approximately 10^-16 GeV.\\n\\nThe question asks about the nature of dark matter and specifically about axion dark matter, which was suggested as a possible candidate based on its predicted gravitational wave signature that could potentially be detectable by future experiments such as LISA (Laser Interferometer Space Antenna) or SKA (Square Kilometer Array). The article discusses numerical simulations and the potential of exploring the existence and properties of axion dark matter through gravitational wave observations.\""
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "document_chain.invoke({\n",
    "    \"input\": question,\n",
    "    \"context\": retriever.invoke(question),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf29c92-7dfd-402d-b13d-bb868e3305ce",
   "metadata": {},
   "source": [
    "However, we want the context to be dynamically generated using the passed input or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37704b84-0dd4-4580-83f8-9a22f4572f0d",
   "metadata": {},
   "source": [
    "From LangChain's documentation: `create_retrieval_chain` adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key `input`, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "08fc17be-fbc6-4cf5-9a10-56b95ff0a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "65b13284-0f97-4d61-af71-d1b80ab78266",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is dark matter?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7fef151e-fa29-437f-8051-160b3da2baba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is dark matter?',\n",
       " 'context': [Document(page_content='  Modern cosmology successfully deals with the origin and the evolution of the\\nUniverse at large scales, but it is unable to completely answer the question\\nabout the nature of the fundamental objects that it is describing. As a matter\\nof fact, about 95\\\\% of the constituents of the Universe is indeed completely\\nunknown: it cannot be described in terms of known particles. Despite intense\\nefforts to shed light on this literal darkness by dark matter and dark energy\\ndirect and indirect searches, not much progress has been made so far. In this\\nwork, we take a different perspective by reviewing and elaborating an old idea\\nof studying the mass-radius distribution of structures in the Universe in\\nrelationship with the fundamental forces acting on them. As we will describe in\\ndetail, the distribution of the observed structures in the Universe is not\\ncompletely random, but it reflects the intimate features of the involved\\nparticles and the nature of the fundamental interactions at play. The observed\\nstructures cluster in restricted regions of the mass-radius diagram linked to\\nknown particles, with the remarkable exception of very large structures that\\nseem to be linked to an unknown particle in the sub-eV mass range. We\\nconjecture that this new particle is a self-interacting dark matter candidate.\\n', metadata={'id': 2112.03755, 'title': 'A new approach to dark matter from the mass-radius diagram of the\\n  Universe', '_id': 'fc4d40da0dc7462091b258df45f01e30', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       "  Document(page_content='  We calculate the accurate spectrum of the stochastic gravitational wave\\nbackground from U(1) gauge fields produced by axion dark matter. The explosive\\nproduction of gauge fields soon invalidates the applicability of the linear\\nanalysis and one needs nonlinear schemes. We make use of numerical lattice\\nsimulations to properly follow the nonlinear dynamics such as backreaction and\\nrescattering which gives important contributions to the emission of\\ngravitational waves. It turns out that the axion with the decay constant $f\\n\\\\sim 10^{16}$ GeV which gives the correct dark matter abundance predicts the\\ncircularly polarized gravitational wave signature detectable by SKA. We also\\nshow that the resulting gravitational wave spectrum has a potential to explain\\nNANOGrav 12.5 year data.\\n', metadata={'id': 2010.1099, 'title': 'Nano-Hz gravitational wave signature from axion dark matter', '_id': '04e3a40776af4041af66b82cfd427537', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})],\n",
       " 'answer': ' Dark matter is a theoretical entity in astrophysics and cosmology that is yet to be directly detected through its observable signals or particles. It is an unseen substance that accounts for approximately 85% of the mass content of the universe, making it an essential component in understanding the structure and evolution of the cosmos (1).\\n\\nThe mysterious nature of dark matter lies in its non-existent presence compared to the visible matter we can detect through our senses or instruments. Although astronomers have discovered numerous celestial objects that cannot be explained by ordinary matter alone, this unexplained mass is significantly more than what can be observed directly. The invisible, yet abundant dark matter particles interact with other matter only through gravity and do not emit, reflect, or absorb any electromagnetic radiation (2).\\n\\nThe term \"dark\" refers to the lack of direct detection of dark matter particles or their signatures in our laboratories. Scientists have hypothesized that these mysterious particles might be uncharged, non-interacting, weakly interacting massive particles (WIMPs), which can explain their absence from our daily experiences. They are thought to have a low mass, typically below a few electron volumes (eV) (3).\\n\\nWhile the exact nature and properties of dark matter remain unknown, some intriguing findings support the existence of WIMPs. These include:\\n\\n1. The rotation curves of galaxies indicate that there must be unseen masses providing gravitational support to the visible matter. This is known as the missing mass problem.\\n2. The cosmic microwave background (CMB) radiation from the early universe reveals an isotropic and homogeneous distribution, which implies a flat, featureless landscape in cosmic scales, but it does not include visible stars or planets. This non-observation of these structures leads us to assume that there must be additional components filling up the extra space (4).\\n3. The gravitational lensing effect observed by astronomers shows an enhancement of the light bending around massive objects, suggesting a substantial amount of hidden mass. This phenomenon is known as strong gravitational lensing (5).\\n\\nThe paper you have provided discusses alternative scenarios to account for these observations, specifically regarding the existence and properties of dark matter particles. By considering self-interacting dark matter candidates with a decay constant of $f\\\\sim 10^{16}$ GeV, they propose an exciting prospect of detecting gravitational waves generated by them using future observatories like SKA (6).\\n\\nIn summary, dark matter is a hypothetical component in the universe that exists as yet undetected invisible particles. Its essential role in shaping the observed astronomical'}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "abea391c-1ce8-49cb-96d2-e5d8e7fb628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical entity in astrophysics and cosmology that is yet to be directly detected through its observable signals or particles. It is an unseen substance that accounts for approximately 85% of the mass content of the universe, making it an essential component in understanding the structure and evolution of the cosmos (1).\n",
      "\n",
      "The mysterious nature of dark matter lies in its non-existent presence compared to the visible matter we can detect through our senses or instruments. Although astronomers have discovered numerous celestial objects that cannot be explained by ordinary matter alone, this unexplained mass is significantly more than what can be observed directly. The invisible, yet abundant dark matter particles interact with other matter only through gravity and do not emit, reflect, or absorb any electromagnetic radiation (2).\n",
      "\n",
      "The term \"dark\" refers to the lack of direct detection of dark matter particles or their signatures in our laboratories. Scientists have hypothesized that these mysterious particles might be uncharged, non-interacting, weakly interacting massive particles (WIMPs), which can explain their absence from our daily experiences. They are thought to have a low mass, typically below a few electron volumes (eV) (3).\n",
      "\n",
      "While the exact nature and properties of dark matter remain unknown, some intriguing findings support the existence of WIMPs. These include:\n",
      "\n",
      "1. The rotation curves of galaxies indicate that there must be unseen masses providing gravitational support to the visible matter. This is known as the missing mass problem.\n",
      "2. The cosmic microwave background (CMB) radiation from the early universe reveals an isotropic and homogeneous distribution, which implies a flat, featureless landscape in cosmic scales, but it does not include visible stars or planets. This non-observation of these structures leads us to assume that there must be additional components filling up the extra space (4).\n",
      "3. The gravitational lensing effect observed by astronomers shows an enhancement of the light bending around massive objects, suggesting a substantial amount of hidden mass. This phenomenon is known as strong gravitational lensing (5).\n",
      "\n",
      "The paper you have provided discusses alternative scenarios to account for these observations, specifically regarding the existence and properties of dark matter particles. By considering self-interacting dark matter candidates with a decay constant of $f\\sim 10^{16}$ GeV, they propose an exciting prospect of detecting gravitational waves generated by them using future observatories like SKA (6).\n",
      "\n",
      "In summary, dark matter is a hypothetical component in the universe that exists as yet undetected invisible particles. Its essential role in shaping the observed astronomical\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7e5c28a6-bc67-4d86-acb1-e8078c8552ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To perform celestial coordinate transformations using the information provided in the context, follow these steps:\n",
      "\n",
      "1. Familiarize yourself with spherical map projections commonly used in astronomy, such as Lambert conical projection and Cylindrical equidistant projection. These are discussed in Paper I of Greisen & Calabretta (2002).\n",
      "\n",
      "2. Understand the new methods implemented in Paper I to assign physical coordinates to FITS image pixels. The paper discusses how to convert informal FITS conventions into these new methods, and vice versa. Detailed examples are provided.\n",
      "\n",
      "3. Learn about header interpretation and construction. This involves using the information within the FITS headers to determine the position of objects in the sky and constructing proper motions and orbital velocities.\n",
      "\n",
      "4. Apply the trigonometric parallax measurement obtained by VERA, VLBA, and monitoring over 25 years. The paper describes how to calculate angular orbital velocities using equatorial coordinates ($\\mu_\\alpha$, $\\mu_\\delta$) and Galactic coordinates ($\\mu_l$, $\\mu_b$). The conversion from equatorial to Galactic coordinates is also discussed in the paper.\n",
      "\n",
      "5. Utilize celestial coordinate transformations that can be applied based on the information provided, such as converting between equatorial and Galactic coordinates or performing conversions involving the Sun's motion. This could include transformations using trigonometric functions or mathematical formulas.\n",
      "\n",
      "6. Take into account any upper limits for core wander, peculiar motion, acceleration, and mass limits of intermediate-mass black holes based on the results obtained by VERA, VLBA, and monitoring over 25 years.\n",
      "\n",
      "Remember to keep in mind the limitations provided in the paper when making coordinate transformations or estimating mass limits for intermediate-mass black holes.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"How can I perform celestial coordinate transformations?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d400004-7320-4915-b493-2996e27b709f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
